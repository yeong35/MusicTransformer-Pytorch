{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faad87db-4531-4435-af23-c2a5ffc860a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from third_party.midi_processor.processor import decode_midi, encode_midi\n",
    "\n",
    "from utilities.argument_funcs import parse_generate_args, print_generate_args\n",
    "from model.music_transformer import MusicTransformer\n",
    "from dataset.e_piano import create_epiano_datasets, compute_epiano_accuracy, process_midi\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from utilities.constants import *\n",
    "from utilities.device import get_device, use_cuda\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bab40378-1e91-4aae-9010-7db5cc8a2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-classic_input_dir\", type=str, default=\"./dataset/e_piano\", help=\"Folder of preprocessed and pickled midi files\")\n",
    "parser.add_argument(\"-pop_input_dir\", type=str, default=\"./dataset/pop_pickle\", help=\"Folder of preprocessed and pickled midi files\")\n",
    "parser.add_argument(\"-output_dir\", type=str, default=\"./saved_models\", help=\"Folder to save model weights. Saves one every epoch\")\n",
    "parser.add_argument(\"-weight_modulus\", type=int, default=10, help=\"How often to save epoch weights (ex: value of 10 means save every 10 epochs)\")\n",
    "parser.add_argument(\"-print_modulus\", type=int, default=50, help=\"How often to print train results for a batch (batch loss, learn rate, etc.)\")\n",
    "\n",
    "parser.add_argument(\"-n_workers\", type=int, default=4, help=\"Number of threads for the dataloader\")\n",
    "parser.add_argument(\"--force_cpu\", action=\"store_true\", help=\"Forces model to run on a cpu even when gpu is available\")\n",
    "parser.add_argument(\"--no_tensorboard\", action=\"store_true\", help=\"Turns off tensorboard result reporting\")\n",
    "\n",
    "parser.add_argument(\"--gan\", action=\"store_true\", help=\"use generative adversarial training\")\n",
    "parser.add_argument(\"--creative\", action=\"store_true\", help=\"creative learning\")\n",
    "\n",
    "parser.add_argument(\"-continue_weights\", type=str, default=None, help=\"Model weights to continue training based on\")\n",
    "parser.add_argument(\"-continue_epoch\", type=int, default=None, help=\"Epoch the continue_weights model was at\")\n",
    "\n",
    "parser.add_argument(\"-lr\", type=float, default=None, help=\"Constant learn rate. Leave as None for a custom scheduler.\")\n",
    "parser.add_argument(\"-ce_smoothing\", type=float, default=0.1, help=\"Smoothing parameter for smoothed cross entropy loss (defaults to no smoothing)\")\n",
    "parser.add_argument(\"-batch_size\", type=int, default=8, help=\"Batch size to use\")\n",
    "parser.add_argument(\"-epochs\", type=int, default=100, help=\"Number of epochs to use\")\n",
    "\n",
    "parser.add_argument(\"--rpr\", action=\"store_true\", help=\"Use a modified Transformer for Relative Position Representations\")\n",
    "parser.add_argument(\"-max_sequence\", type=int, default=1536, help=\"Maximum midi sequence to consider\")\n",
    "parser.add_argument(\"-n_layers\", type=int, default=6, help=\"Number of decoder layers to use\")\n",
    "parser.add_argument(\"-num_heads\", type=int, default=8, help=\"Number of heads to use for multi-head attention\")\n",
    "parser.add_argument(\"-d_model\", type=int, default=512, help=\"Dimension of the model (output dim of embedding layers, etc.)\")\n",
    "\n",
    "parser.add_argument(\"-dim_feedforward\", type=int, default=1024, help=\"Dimension of the feedforward layer\")\n",
    "parser.add_argument(\"-num_prime\", type=int, default=256, help=\"Amount of messages to prime the generator with\")\n",
    "\n",
    "parser.add_argument(\"-target_seq_length\", type=int, default=1024, help=\"Target length you'd like the midi to be\")\n",
    "# parser.add_argument(\"-num_prime\", type=int, default=256, help=\"Amount of messages to prime the generator with\")\n",
    "# parser.add_argument(\"-model_weights\", type=str, default=\"./saved_models/model.pickle\", help=\"Pickled model weights file saved with torch.save and model.state_dict()\")\n",
    "parser.add_argument(\"-beam\", type=int, default=0, help=\"Beam search k. 0 for random probability sample and 1 for greedy\")\n",
    "\n",
    "parser.add_argument(\"-dropout\", type=float, default=0.1, help=\"Dropout rate\")\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f16e657c-119a-4bac-9d98-dea81f88b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.rpr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43cfc5b5-e164-4171-8e90-942769c28d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# argument parsing\\\n",
    "\n",
    "if(args.force_cpu):\n",
    "    use_cuda(False)\n",
    "    print(\"WARNING: Forced CPU usage, expect model to perform slower\")\n",
    "    print(\"\")\n",
    "\n",
    "# 저장할 directory 만들기\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "os.makedirs(args.output_dir+'/classic/', exist_ok=True)\n",
    "os.makedirs(args.output_dir+'/pop/', exist_ok=True)\n",
    "\n",
    "# Grabbing dataset if needed\n",
    "# pickle file path - EY\n",
    "classic_path = './dataset/e_piano/'\n",
    "pop_path = './dataset/pop_trainvalid/'\n",
    "\n",
    "# train, val, test\n",
    "classic_train, classic_eval, classic_test = create_epiano_datasets(classic_path, args.num_prime, random_seq=False)\n",
    "pop_train, pop_eval, pop_test = create_epiano_datasets(pop_path, args.num_prime, random_seq=False)\n",
    "\n",
    "classic_dataset = [classic_train, classic_eval, classic_test]\n",
    "pop_dataset = [pop_train, pop_eval, pop_test]\n",
    "dataset_folder = ['train/', 'val/', 'test/']\n",
    "\n",
    "# Can be None, an integer index to dataset, or a file path\n",
    "# if(args.primer_file is None):\n",
    "#     f = str(random.randrange(len(dataset)))\n",
    "# else:\n",
    "#     f = args.primer_file\n",
    "\n",
    "# if(f.isdigit()):\n",
    "#     idx = int(f)\n",
    "#     primer, _, _  = dataset[idx]\n",
    "#     primer = primer.to(get_device())\n",
    "#\n",
    "#     print(\"Using primer index:\", idx, \"(\", dataset.data_files[idx], \")\")\n",
    "#\n",
    "# else:\n",
    "#     raw_mid = encode_midi(f)\n",
    "#     if(len(raw_mid) == 0):\n",
    "#         print(\"Error: No midi messages in primer file:\", f)\n",
    "#         return\n",
    "#\n",
    "#     primer, _  = process_midi(raw_mid, args.num_prime, random_seq=False)\n",
    "#     primer = torch.tensor(primer, dtype=TORCH_LABEL_TYPE, device=get_device())\n",
    "#\n",
    "#     print(\"Using primer file:\", f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1030a992-6434-4549-93e8-158f6c722da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using primer index: 0 ( ./dataset/pop_trainvalid/train/883.pickle )\n",
      "RAND DIST\n",
      "Done!\n",
      "Using primer index: 0 ( ./dataset/pop_trainvalid/val/109.pickle )\n",
      "RAND DIST\n",
      "Done!\n",
      "Using primer index: 0 ( ./dataset/pop_trainvalid/test/080.pickle )\n",
      "RAND DIST\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# pop generation\n",
    "for dataset, folder in zip(pop_dataset, dataset_folder):\n",
    "\n",
    "    pop_index_list = list(range(len(dataset)))\n",
    "    folder_name_length = len(folder)\n",
    "\n",
    "    for pop_index in pop_index_list:\n",
    "        primer, _, _ = dataset[pop_index]\n",
    "        primer = primer.to(get_device())\n",
    "        print(\"Using primer index:\", pop_index, \"(\", dataset.data_files[pop_index], \")\")\n",
    "\n",
    "        # # Saving primer first\n",
    "        # f_path = os.path.join(args.output_dir, f\"primer_{pop_dataset.data_files[pop_index][len(classic_path)+5:]}.mid\")\n",
    "        # decode_midi(primer[:args.num_prime].cpu().numpy(), file_path=f_path)\n",
    "\n",
    "        print(\"RAND DIST\")\n",
    "#         rand_seq = model.generate(primer[:args.num_prime], args.target_seq_length, beam=0)\n",
    "\n",
    "        f_path = os.path.join(\n",
    "            args.output_dir+'/pop/', f\"rand_{dataset.data_files[pop_index][len(pop_path)+folder_name_length:]}.mid\")\n",
    "        decode_midi(primer.cpu().numpy(), file_path=f_path)\n",
    "        print(\"Done!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc7a827b-e9cf-41d2-acb4-0795ff6f866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(primer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192d1c32-8a0f-495a-904f-88a2c6bab2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models/pop/rand_080.pickle.mid'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1279e85-e8a6-44ed-878a-3337eac10c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
