{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9e8e20-926f-4b53-bc08-9112d97dfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import csv\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset.e_piano import create_epiano_datasets, create_pop909_datasets\n",
    "\n",
    "from model.music_transformer import MusicTransformer\n",
    "\n",
    "from model.discriminator import MusicDiscriminator\n",
    "\n",
    "from model.loss import SmoothCrossEntropyLoss\n",
    "\n",
    "from utilities.constants import *\n",
    "from utilities.WGAN_GP import WassersteinLoss\n",
    "from utilities.device import get_device, use_cuda\n",
    "from utilities.lr_scheduling import LrStepTracker, get_lr\n",
    "from utilities.argument_funcs import parse_train_args, print_train_args, write_model_params\n",
    "from utilities.run_model import train_epoch, eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dac2598-acfd-4d85-8d51-2c7ba4a57379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e25ed0-8927-4fad-ad91-bad67121c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-classic_input_dir\", type=str, default=\"./dataset/e_piano\", help=\"Folder of preprocessed and pickled midi files\")\n",
    "parser.add_argument(\"-pop_input_dir\", type=str, default=\"./dataset/pop_pickle\", help=\"Folder of preprocessed and pickled midi files\")\n",
    "parser.add_argument(\"-output_dir\", type=str, default=\"./saved_models\", help=\"Folder to save model weights. Saves one every epoch\")\n",
    "parser.add_argument(\"-weight_modulus\", type=int, default=10, help=\"How often to save epoch weights (ex: value of 10 means save every 10 epochs)\")\n",
    "parser.add_argument(\"-print_modulus\", type=int, default=50, help=\"How often to print train results for a batch (batch loss, learn rate, etc.)\")\n",
    "\n",
    "parser.add_argument(\"-n_workers\", type=int, default=4, help=\"Number of threads for the dataloader\")\n",
    "parser.add_argument(\"--force_cpu\", action=\"store_true\", help=\"Forces model to run on a cpu even when gpu is available\")\n",
    "parser.add_argument(\"--no_tensorboard\", action=\"store_true\", help=\"Turns off tensorboard result reporting\")\n",
    "\n",
    "parser.add_argument(\"--gan\", action=\"store_true\", help=\"use generative adversarial training\")\n",
    "parser.add_argument(\"--creative\", action=\"store_true\", help=\"creative learning\")\n",
    "\n",
    "parser.add_argument(\"-continue_weights\", type=str, default=None, help=\"Model weights to continue training based on\")\n",
    "parser.add_argument(\"-continue_epoch\", type=int, default=None, help=\"Epoch the continue_weights model was at\")\n",
    "\n",
    "parser.add_argument(\"-lr\", type=float, default=None, help=\"Constant learn rate. Leave as None for a custom scheduler.\")\n",
    "parser.add_argument(\"-ce_smoothing\", type=float, default=0.1, help=\"Smoothing parameter for smoothed cross entropy loss (defaults to no smoothing)\")\n",
    "parser.add_argument(\"-batch_size\", type=int, default=32, help=\"Batch size to use\")\n",
    "parser.add_argument(\"-epochs\", type=int, default=100, help=\"Number of epochs to use\")\n",
    "\n",
    "parser.add_argument(\"--rpr\", action=\"store_true\", help=\"Use a modified Transformer for Relative Position Representations\")\n",
    "parser.add_argument(\"-max_sequence\", type=int, default=1536, help=\"Maximum midi sequence to consider\")\n",
    "parser.add_argument(\"-n_layers\", type=int, default=6, help=\"Number of decoder layers to use\")\n",
    "parser.add_argument(\"-num_heads\", type=int, default=8, help=\"Number of heads to use for multi-head attention\")\n",
    "parser.add_argument(\"-d_model\", type=int, default=512, help=\"Dimension of the model (output dim of embedding layers, etc.)\")\n",
    "\n",
    "parser.add_argument(\"-dim_feedforward\", type=int, default=1024, help=\"Dimension of the feedforward layer\")\n",
    "\n",
    "parser.add_argument(\"-dropout\", type=float, default=0.1, help=\"Dropout rate\")\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f09962d9-2a35-4806-bb16-2602a9d55a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.rpr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db3abbd-1e2c-413a-aed8-4878ef3d48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(args.lr is None):\n",
    "    if(args.continue_epoch is None):\n",
    "        init_step = 0\n",
    "    else:\n",
    "        init_step = args.continue_epoch * len(train_loader)\n",
    "\n",
    "    lr = LR_DEFAULT_START\n",
    "    lr_stepper = LrStepTracker(args.d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
    "else:\n",
    "    lr = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "398cab85-2f9f-4547-8344-534228cc8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_epiano_datasets(args.classic_input_dir, args.max_sequence)\n",
    "\n",
    "\n",
    "pop909_dataset = create_pop909_datasets('dataset/pop_pickle', args.max_sequence)\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(pop909_dataset, [int(len(pop909_dataset) * 0.8), int(len(pop909_dataset) * 0.1), len(pop909_dataset) - int(len(pop909_dataset) * 0.8) - int(len(pop909_dataset) * 0.1)])\n",
    "\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset, train_set])\n",
    "val_dataset = torch.utils.data.ConcatDataset([val_dataset, val_set])\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=args.n_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.n_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=args.n_workers)\n",
    "\n",
    "classifier = MusicDiscriminator(n_layers=args.n_layers // 2, num_heads=args.num_heads // 2,\n",
    "                             d_model=args.d_model // 2, dim_feedforward=args.dim_feedforward // 2, dropout=args.dropout,\n",
    "                             max_sequence=args.max_sequence, rpr=args.rpr).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a21e0cd3-34fe-45f5-bd38-e0d9bbc06bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b77c5957-4432-40ef-8397-bed11c969192",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9558207e-c033-4f31-9572-e15a27a38a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_opt = Adam(classifier.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
    "\n",
    "if(args.lr is None):\n",
    "    classifier_lr_scheduler = LambdaLR(classifier_opt, lr_stepper.step)\n",
    "else:\n",
    "    lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02de85db-90b5-4d8a-810c-774dd8b8779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.print_modulus = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c5e5e-811d-465a-88b1-ea0bedca02b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n",
      "torch.Size([32, 1536, 390])\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(300):\n",
    "    \n",
    "    train_acc_cla_loss = 0\n",
    "    train_acc_class_accuracy = 0\n",
    "    \n",
    "    classifier.train()\n",
    "\n",
    "    for batch_num, batch in enumerate(train_loader):\n",
    "        time_before = time.time()\n",
    "\n",
    "        x   = batch[0].to(get_device())\n",
    "        tgt = batch[1].to(get_device())\n",
    "        label = batch[2].to(get_device())\n",
    "        \n",
    "        tgt = F.one_hot(tgt, num_classes = VOCAB_SIZE).float()\n",
    "\n",
    "        classifier_pred = classifier(tgt)\n",
    "\n",
    "        class_loss = classifier_loss(classifier_pred, label.float())\n",
    "\n",
    "        classifier_opt.zero_grad()\n",
    "        class_loss.backward()\n",
    "        classifier_opt.step()\n",
    "\n",
    "        train_acc_cla_loss += float(class_loss)\n",
    "\n",
    "        train_acc_class_accuracy += ((classifier_pred > 0.5).float() == label).float().mean()\n",
    "\n",
    "        if classifier_lr_scheduler is not None:\n",
    "            classifier_lr_scheduler.step()\n",
    "        \n",
    "    val_acc_cla_loss = 0\n",
    "    val_acc_class_accuracy = 0\n",
    "    \n",
    "    classifier.eval()\n",
    "        \n",
    "    for batch_num, batch in enumerate(val_loader):\n",
    "        time_before = time.time()\n",
    "\n",
    "        x   = batch[0].to(get_device())\n",
    "        tgt = batch[1].to(get_device())\n",
    "        label = batch[2].to(get_device())\n",
    "        \n",
    "        tgt = F.one_hot(tgt, num_classes = VOCAB_SIZE).float()\n",
    "\n",
    "        classifier_pred = classifier(tgt)\n",
    "\n",
    "        class_loss = classifier_loss(classifier_pred, label.float())\n",
    "\n",
    "        val_acc_cla_loss += float(class_loss)\n",
    "\n",
    "        val_acc_class_accuracy += ((classifier_pred > 0.5).float() == label).float().mean()\n",
    "\n",
    "        #if classifier_lr_scheduler is not None:\n",
    "        #    classifier_lr_scheduler.step()\n",
    "        \n",
    "        \n",
    "    if float(val_acc_class_accuracy) / len(val_loader) > best_acc:\n",
    "        best_acc = float(val_acc_class_accuracy) / len(val_loader)\n",
    "        torch.save(classifier.state_dict(), f'best_classifier_acc_{best_acc:.4f}.pickle')\n",
    "        \n",
    "        \n",
    "    print(SEPERATOR)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(\n",
    "        f\"Classifier LR: {get_lr(classifier_opt)}\")\n",
    "    print(f\"Classifier Train Loss: {train_acc_cla_loss / len(train_loader):.5f}, Val Loss: {val_acc_cla_loss / len(val_loader):.5f}\")\n",
    "    print(f\"Classifier Train Accuracy: {float(train_acc_class_accuracy) / len(train_loader):.5f}, Val Accuracy: {float(val_acc_class_accuracy) / len(val_loader):.5f}\")\n",
    "    print(SEPERATOR)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcaa9b-247c-4b00-a10f-7e1d78e8c648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
